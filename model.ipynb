{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "import en_core_web_sm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# stopwords = nlp.Defaults.stop_words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from pprint import pprint\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import preprocessing\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#options\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    clean_text = re.sub('\\S*\\d\\S*\\s*', '', clean_text)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuation = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return punctuation\n",
    "\n",
    "def convert_to_lowercase(text):\n",
    "    text_lower = text.lower()\n",
    "    return text_lower\n",
    "\n",
    "def tokenization(text):\n",
    "    tokens  = word_tokenize(text)\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "    \n",
    "\n",
    "def lem_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemma = ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return lemma\n",
    "\n",
    "def replace(text):\n",
    "    replaced = text.replace('xxxx', '').replace('-PRON-', '')\n",
    "\n",
    "    return replaced\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge cleaning functions for one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(text):\n",
    "    \n",
    "    text = remove_special_characters(text) #pass\n",
    "    text = remove_punctuation(text) #pass\n",
    "    text = convert_to_lowercase(text) #pass\n",
    "    text = tokenization(text) #pass\n",
    "    text = remove_stopwords(text) #pass\n",
    "    text = lem_text(text) #pass\n",
    "    text = replace(text) #pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Restore basic forms of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    lem_tokens = [token.lemma_ for token in doc if token.text.lower() not in STOP_WORDS]\n",
    "    lem_text = ' '.join(lem_tokens)\n",
    "    \n",
    "    return lem_text\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stem_words = [stemmer.stem(word) for word in words if word.text.lower() not in STOP_WORDS]\n",
    "    stem_text = ' '.join(stem_words)\n",
    "\n",
    "    return stem_text\n",
    "\n",
    "def remove_POS_tags(text):\n",
    "    doc = nlp(text)\n",
    "    result = [token.text for token in doc if token.tag_ == 'NN']  # check for nouns\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection+Credit card debt</td>\n",
       "      <td>[morning, name, stop, cardmember, debt, verifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card+General-purpose cr...</td>\n",
       "      <td>[XXXX, XXXX, card, agent, anniversary, date, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[application, identity, consent, credit, ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[XXXX, ticket, offer, ticket, card, informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account+Checking account</td>\n",
       "      <td>[son, chase, account, fund, chase, bank, accou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       complaint_text  \\\n",
       "1   Good morning my name is XXXX XXXX and I apprec...   \n",
       "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "10  Chase Card was reported on XX/XX/2019. However...   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "14  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                                             category  \\\n",
       "1                    Debt collection+Credit card debt   \n",
       "2   Credit card or prepaid card+General-purpose cr...   \n",
       "10  Credit reporting, credit repair services, or o...   \n",
       "11  Credit reporting, credit repair services, or o...   \n",
       "14       Checking or savings account+Checking account   \n",
       "\n",
       "                                                clean  \n",
       "1   [morning, name, stop, cardmember, debt, verifi...  \n",
       "2   [XXXX, XXXX, card, agent, anniversary, date, a...  \n",
       "10  [application, identity, consent, credit, ident...  \n",
       "11  [XXXX, ticket, offer, ticket, card, informatio...  \n",
       "14  [son, chase, account, fund, chase, bank, accou...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "data['clean1'] = data['complaint_text'].apply(lambda x: lemmatization(x))\n",
    "data['clean2'] = data['complaint_text'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection+Credit card debt</td>\n",
       "      <td>Good morning name XXXX XXXX appreciate could h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card+General-purpose cr...</td>\n",
       "      <td>upgraded XXXX XXXX card XX/XX/2018 told agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Chase Card reported XX/XX/2019 . However , fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>XX/XX/2018 , trying book XXXX XXXX ticket , ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account+Checking account</td>\n",
       "      <td>grand son give check { $ 1600.00 } deposit cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       complaint_text  \\\n",
       "1   Good morning my name is XXXX XXXX and I apprec...   \n",
       "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "10  Chase Card was reported on XX/XX/2019. However...   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "14  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                                             category  \\\n",
       "1                    Debt collection+Credit card debt   \n",
       "2   Credit card or prepaid card+General-purpose cr...   \n",
       "10  Credit reporting, credit repair services, or o...   \n",
       "11  Credit reporting, credit repair services, or o...   \n",
       "14       Checking or savings account+Checking account   \n",
       "\n",
       "                                                clean  \n",
       "1   Good morning name XXXX XXXX appreciate could h...  \n",
       "2   upgraded XXXX XXXX card XX/XX/2018 told agent ...  \n",
       "10  Chase Card reported XX/XX/2019 . However , fra...  \n",
       "11  XX/XX/2018 , trying book XXXX XXXX ticket , ca...  \n",
       "14  grand son give check { $ 1600.00 } deposit cha...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset - https://www.kaggle.com/datasets/abhishek14398/automatic-ticket-classification-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"complaints.json\"\n",
    "open_path = open(path) \n",
    "read_data = json.load(open_path)\n",
    "df=pd.json_normalize(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['_source.complaint_what_happened','_source.product','_source.sub_product']]\n",
    "df = df.rename(columns={'_source.complaint_what_happened': 'complaint_text', '_source.product': 'category','_source.sub_product': 'sub_category'})\n",
    "\n",
    "# data modelling\n",
    "df['category'] = df['category'] + '+' + df['sub_category']\n",
    "df = df.drop(['sub_category'],axis= 1)\n",
    "df[df['complaint_text']==''] = np.nan\n",
    "df = df[~df['complaint_text'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection+Credit card debt</td>\n",
       "      <td>[morning, name, appreciate, bank, service, wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card+General-purpose cr...</td>\n",
       "      <td>[card, agent, upgrade, anniversary, date, agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[chase, card, report, application, submit, ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[book, ticket, offer, ticket, reward, card, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account+Checking account</td>\n",
       "      <td>[son, check, deposit, chase, account, fund, ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       complaint_text  \\\n",
       "1   Good morning my name is XXXX XXXX and I apprec...   \n",
       "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "10  Chase Card was reported on XX/XX/2019. However...   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "14  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                                             category  \\\n",
       "1                    Debt collection+Credit card debt   \n",
       "2   Credit card or prepaid card+General-purpose cr...   \n",
       "10  Credit reporting, credit repair services, or o...   \n",
       "11  Credit reporting, credit repair services, or o...   \n",
       "14       Checking or savings account+Checking account   \n",
       "\n",
       "                                                clean  \n",
       "1   [morning, name, appreciate, bank, service, wri...  \n",
       "2   [card, agent, upgrade, anniversary, date, agen...  \n",
       "10  [chase, card, report, application, submit, ide...  \n",
       "11  [book, ticket, offer, ticket, reward, card, in...  \n",
       "14  [son, check, deposit, chase, account, fund, ac...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df # replace to have possibility to load back original data\n",
    "data['clean'] = data['complaint_text'].apply(lambda x: preprocessing_data(x)) # new column with preprocessed data\n",
    "data['clean'] = data['clean'].apply(lambda x: lemmatization(x))\n",
    "# data['clean'] = data['complaint_text'].apply(preprocessing_data) # new column with preprocessed data\n",
    "# data['clean'] = data['complaint_text'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# doc_lens = [len(d) for d in data.clean]\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m doc_lens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcategory]\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(doc_lens, bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here to visualise the data according to the 'Complaint' character length\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# doc_lens = [len(d) for d in data.clean]\n",
    "doc_lens = [len(d) for d in data.clean]\n",
    "plt.hist(doc_lens, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection+Credit card debt</td>\n",
       "      <td>[morning, name, appreciate, bank, service, wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card+General-purpose cr...</td>\n",
       "      <td>[card, agent, upgrade, anniversary, date, agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[chase, card, report, application, submit, ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>[book, ticket, offer, ticket, reward, card, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account+Checking account</td>\n",
       "      <td>[son, check, deposit, chase, account, fund, ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       complaint_text  \\\n",
       "1   Good morning my name is XXXX XXXX and I apprec...   \n",
       "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "10  Chase Card was reported on XX/XX/2019. However...   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "14  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                                             category  \\\n",
       "1                    Debt collection+Credit card debt   \n",
       "2   Credit card or prepaid card+General-purpose cr...   \n",
       "10  Credit reporting, credit repair services, or o...   \n",
       "11  Credit reporting, credit repair services, or o...   \n",
       "14       Checking or savings account+Checking account   \n",
       "\n",
       "                                                clean  \n",
       "1   [morning, name, appreciate, bank, service, wri...  \n",
       "2   [card, agent, upgrade, anniversary, date, agen...  \n",
       "10  [chase, card, report, application, submit, ide...  \n",
       "11  [book, ticket, offer, ticket, reward, card, in...  \n",
       "14  [son, check, deposit, chase, account, fund, ac...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "### in this dataset I have too much categories, so my plan is to change quantity of categories to 5.\n",
    "### This can be done by NFM or LDA\n",
    "###\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vectorizer - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(min_df=2, max_df=0.95, stop_words='english')\n",
    "# vectorizer_matrix = vectorizer.fit_transform(data['clean'])\n",
    "# vectorizer.get_feature_names_out()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# NFM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
