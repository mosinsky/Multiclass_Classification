{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from scipy import interp\n",
    "# import numpy as np\n",
    "\n",
    "# def classification(classifier, X_train, X_test, y_train, y_test,model_name):\n",
    "#     # Fit the classifier on the training data\n",
    "#     classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # Predictions on training and testing sets\n",
    "#     y_train_pred = classifier.predict(X_train)\n",
    "#     y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "#     # Extract unique classes from the target variable\n",
    "#     unique_classes = np.unique(np.concatenate([y_train, y_test]))\n",
    "\n",
    "#     # Convert labels to binary format for ROC curve\n",
    "#     y_train_bin = label_binarize(y_train, classes=unique_classes)\n",
    "#     y_test_bin = label_binarize(y_test, classes=unique_classes)\n",
    "\n",
    "#     # Compute ROC curve and ROC area for each class\n",
    "#     n_classes = len(unique_classes)\n",
    "#     fpr = dict()\n",
    "#     tpr = dict()\n",
    "#     roc_auc = dict()\n",
    "\n",
    "#     for i in range(n_classes):\n",
    "#         fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], classifier.predict_proba(X_test)[:, i])\n",
    "#         roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "#     # Compute micro-average ROC curve and ROC area\n",
    "#     fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), classifier.predict_proba(X_test).ravel())\n",
    "#     roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "\n",
    "#     # Accuracy Scores\n",
    "#     train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "#     test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "#     # Classification Report\n",
    "#     print(\"\\nTraining Accuracy:\", train_accuracy)\n",
    "#     print(\"\\nTraining Classification Report:\")\n",
    "#     print(classification_report(y_train, y_train_pred, target_names=unique_classes))\n",
    "\n",
    "#     print(\"Testing Accuracy:\", test_accuracy)\n",
    "#     print(\"\\nTesting Classification Report:\")\n",
    "#     print(classification_report(y_test, y_test_pred, target_names=unique_classes))\n",
    "\n",
    "    \n",
    "#     # Plot ROC curve\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})', linestyle=':', linewidth=4)\n",
    "\n",
    "#     for i in range(n_classes):\n",
    "#         plt.plot(fpr[i], tpr[i], label=f'ROC curve for class {unique_classes[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "#     plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Confusion Matrix\n",
    "#     cm = confusion_matrix(y_test, y_test_pred)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(unique_classes))\n",
    "#     plt.xticks(tick_marks, unique_classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, unique_classes)\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     metrics_dict = {\n",
    "#         'model': model_name,\n",
    "#         'Training Accuracy': train_accuracy,\n",
    "#         'Testing Accuracy': test_accuracy,\n",
    "#         'Micro-average ROC AUC': roc_auc[\"micro\"],\n",
    "#         # 'Confusion Matrix': [cm]\n",
    "#         # 'Training Classification Report': [train_classification_report],\n",
    "#         # 'Testing Classification Report': [test_classification_report]\n",
    "#     }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
